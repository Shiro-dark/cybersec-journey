## 🧠 Daily Log – June 2, 2025

---

### 🔥 Focus

Crushing ML fundamentals using the Titanic dataset — diving into `pandas`, Jupyter, and your first classifier model.

---

### 🛠️ What I Did

- **Explored Pandas for Data Wrangling:**
  - Loaded CSVs using `read_csv`
  - Used `.head()`, filtered, sorted, filled nulls
  - Mapped string values to integers (e.g. `Sex`, `Embarked`)

- **Analyzed Titanic Dataset:**
  - Identified survival patterns (rich girls survived, poor boys didn’t)
  - Checked age groups (children had better survival odds)
  - Examined `SibSp`, `Parch`, `Pclass` for relational insights

- **Jupyter Notebook Work:**
  - Ran Python code cell-by-cell
  - Visualized data content clearly
  - Built clean and reproducible preprocessing steps

- **Built ML Model:**
  - Used `RandomForestClassifier` from `sklearn`
  - Preprocessed features (encoded + filled missing values)
  - Trained the model and made predictions
  - Submitted to Kaggle → Scored **0.73684** on the first attempt

- **Kaggle Workflow:**
  - Downloaded challenge dataset
  - Trained, predicted, and submitted
  - Evaluated against public leaderboard

---

### 🧠 Lessons Learned

- Pandas = your SQL-meets-JS playground for data analysis
- Jupyter is perfect for building clean ML workflows step-by-step
- Feature preprocessing is **key** to solid model performance
- `RandomForestClassifier` is strong for starters
- First Kaggle score above 0.73 = you’re not learning, you’re executing

---

### ✅ Summary

- Hands-on pandas, sklearn, and data cleaning  
- First end-to-end ML pipeline built and tested  
- Cracked Titanic challenge with solid Kaggle score  
